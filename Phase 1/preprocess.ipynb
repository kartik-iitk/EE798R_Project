{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Intelligent Pattern Recognition, EE798R\n",
    "\n",
    "##### *October 20th, 2024*\n",
    "\n",
    "# Project Paper 1 (TIMNET) - Dataset Preprocessing\n",
    "\n",
    "**Kartik Anant Kulkarni (Section C, Roll no. 210493)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "from typing import Tuple\n",
    "from tqdm import tqdm\n",
    "from python_speech_features import *\n",
    "import librosa\n",
    "import librosa.display\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import argparse\n",
    "from natsort import ns, natsorted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Hyperparameters\n",
    "\n",
    "Copy the raw dataset, for e.g., `SAVEE` from the `./Raw_Datasets./` directory to the `./Datasets` directory and set the hyperparameters based on the dataset, from the following table, in the next cell.\n",
    "\n",
    "| data_name | mean_signal_length |\n",
    "| --------- | --------- |\n",
    "| SAVEE     | 130000    |\n",
    "| EMODB     | 96000     |\n",
    "| IEMOCAP   | 310000    |\n",
    "| EMOVO     | 96000     |\n",
    "| RAVDE     | 110000    |\n",
    "| CASIA     | 88000     |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "\n",
    "parser.add_argument(\"--mean_signal_length\", type=int, default=130000)\n",
    "parser.add_argument(\"--data_name\", type=str, default=\"SAVEE\")\n",
    "args, _ = parser.parse_known_args()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions\n",
    "\n",
    "Following functions convert the data to `csv` files and subsequently into the MFCCs on being called in the execution order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feature(\n",
    "    file_path: str,\n",
    "    feature_type: str = \"MFCC\",\n",
    "    mean_signal_length: int = 96000,\n",
    "    embed_len: int = 39,\n",
    "):\n",
    "    feature = None\n",
    "    signal, fs = librosa.load(file_path)  # Default setting on sampling rate\n",
    "    s_len = len(signal)\n",
    "    if s_len < mean_signal_length:\n",
    "        pad_len = mean_signal_length - s_len\n",
    "        pad_rem = pad_len % 2\n",
    "        pad_len //= 2\n",
    "        signal = np.pad(\n",
    "            signal, (pad_len, pad_len + pad_rem), \"constant\", constant_values=0\n",
    "        )\n",
    "    else:\n",
    "        pad_len = s_len - mean_signal_length\n",
    "        pad_len //= 2\n",
    "        signal = signal[pad_len : pad_len + mean_signal_length]\n",
    "    if feature_type == \"MFCC\":\n",
    "        mfcc = librosa.feature.mfcc(y=signal, sr=fs, n_mfcc=embed_len)\n",
    "        feature = np.transpose(mfcc)\n",
    "    return feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_csv(\n",
    "    csv_save: str,\n",
    "    data_name: str = \"EMODB\",\n",
    "    feature_type: str = \"MFCC\",\n",
    "    embed_len: int = 39,\n",
    "    mean_signal_length: int = 96000,\n",
    "    class_labels: Tuple = (\n",
    "        \"angry\",\n",
    "        \"boredom\",\n",
    "        \"disgust\",\n",
    "        \"fear\",\n",
    "        \"happy\",\n",
    "        \"neutral\",\n",
    "        \"sad\",\n",
    "    ),\n",
    "):\n",
    "    data_path = \"./Datasets/\" + data_name  # Modify this path\n",
    "    current_dir = os.getcwd()\n",
    "    if not os.path.exists(csv_save):\n",
    "        print(csv_save + \" build succeed\")\n",
    "        os.makedirs(csv_save)\n",
    "        os.chdir(csv_save)\n",
    "    else:\n",
    "        os.chdir(csv_save)\n",
    "    for i, directory in enumerate(class_labels):\n",
    "        if not os.path.exists(directory):\n",
    "            os.makedirs(directory)\n",
    "            print(directory + \" build succeed\")\n",
    "    os.chdir(\"..\")\n",
    "    datapath = []\n",
    "    labels = []\n",
    "    sys.stderr.write(\"Current Folder: %s\\n\" % current_dir)\n",
    "    os.chdir(data_path)\n",
    "    for i, directory in enumerate(class_labels):\n",
    "        sys.stderr.write(\"Start to Read %s\\n\" % directory)\n",
    "        if not os.path.exists(directory):\n",
    "            os.makedirs(directory)\n",
    "            os.chdir(directory)\n",
    "            print(directory + \" build succeed\")\n",
    "        else:\n",
    "            os.chdir(directory)\n",
    "        for filename in tqdm(os.listdir(\".\")):\n",
    "            if not filename.endswith(\"wav\"):\n",
    "                continue\n",
    "            filepath = os.getcwd() + \"/\" + filename\n",
    "            datapath.append(filepath)\n",
    "            labels.append(i)\n",
    "        sys.stderr.write(\"End to Read %s\\n\" % directory)\n",
    "        os.chdir(\"..\")\n",
    "    os.chdir(current_dir)\n",
    "    temp_size_ = True\n",
    "    for video_path, label in tqdm(zip(datapath, labels)):\n",
    "        filename = video_path[video_path.rfind(\"/\") + 1 : -4]\n",
    "        feature_vector = get_feature(\n",
    "            file_path=video_path,\n",
    "            feature_type=feature_type,\n",
    "            mean_signal_length=mean_signal_length,\n",
    "            embed_len=embed_len,\n",
    "        )\n",
    "        if temp_size_:\n",
    "            print(f\"### Feature Size:{feature_vector.shape} ###\")\n",
    "            temp_size_ = False\n",
    "        np.savetxt(\n",
    "            csv_save + \"/\" + class_labels[label] + \"/\" + filename + \"_raw\" + \".csv\",\n",
    "            feature_vector,\n",
    "            delimiter=\",\",\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_csv(\n",
    "    data_path: str,\n",
    "    mfcc_len: int = 39,\n",
    "    class_labels: Tuple = (\n",
    "        \"angry\",\n",
    "        \"boredom\",\n",
    "        \"disgust\",\n",
    "        \"fear\",\n",
    "        \"happy\",\n",
    "        \"neutral\",\n",
    "        \"sad\",\n",
    "    ),\n",
    "    flatten: bool = False,\n",
    "):\n",
    "    x = []\n",
    "    y = []\n",
    "    current_dir = os.getcwd()\n",
    "    sys.stderr.write(\"Current Folder: %s\\n\" % current_dir)\n",
    "    os.chdir(data_path)\n",
    "    for i, directory in enumerate(class_labels):\n",
    "        sys.stderr.write(\"Start to Read %s\\n\" % directory)\n",
    "        os.chdir(directory)\n",
    "        file_list = os.listdir(\".\")\n",
    "        # file_list.sort(key=str.lower)# Sort by the file name\n",
    "        file_list = natsorted(file_list, alg=ns.PATH)\n",
    "        for filename in tqdm(file_list):\n",
    "            if not filename.endswith(\".csv\"):\n",
    "                continue\n",
    "            if filename.endswith(\"time.csv\"):\n",
    "                continue\n",
    "            filepath = os.getcwd() + \"/\" + filename\n",
    "            feature_vector = np.loadtxt(\n",
    "                filepath, delimiter=\",\", dtype=np.float32, encoding=\"gbk\"\n",
    "            )\n",
    "            x.append(feature_vector)\n",
    "            y.append(i)\n",
    "        sys.stderr.write(\"End to Read %s\\n\" % directory)\n",
    "        os.chdir(\"..\")\n",
    "    os.chdir(current_dir)\n",
    "    return np.array(x), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_feature(\n",
    "    data_name: str,\n",
    "    feature_type_: str = \"MFCC\",\n",
    "    mean_signal_length: int = 96000,\n",
    "    class_labels: Tuple = (\n",
    "        \"angry\",\n",
    "        \"boredom\",\n",
    "        \"disgust\",\n",
    "        \"fear\",\n",
    "        \"happy\",\n",
    "        \"neutral\",\n",
    "        \"sad\",\n",
    "    ),\n",
    "):\n",
    "    csv_save = (\n",
    "        \"./\"\n",
    "        + data_name\n",
    "        + \"_\"\n",
    "        + feature_type_\n",
    "        + \"_\"\n",
    "        + str(int(mean_signal_length / 1000))\n",
    "    )\n",
    "    generate_csv(\n",
    "        csv_save=csv_save,\n",
    "        data_name=data_name,\n",
    "        class_labels=class_labels,\n",
    "        feature_type=feature_type_,\n",
    "        mean_signal_length=mean_signal_length,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMODB_LABEL = (\"angry\", \"boredom\", \"disgust\", \"fear\", \"happy\", \"neutral\", \"sad\")\n",
    "CASIA_LABEL = (\"angry\", \"fear\", \"happy\", \"neutral\", \"sad\", \"surprise\")\n",
    "SAVEE_LABEL = (\"angry\", \"disgust\", \"fear\", \"happy\", \"neutral\", \"sad\", \"surprise\")\n",
    "RAVDE_LABEL = (\n",
    "    \"angry\",\n",
    "    \"calm\",\n",
    "    \"disgust\",\n",
    "    \"fear\",\n",
    "    \"happy\",\n",
    "    \"neutral\",\n",
    "    \"sad\",\n",
    "    \"surprise\",\n",
    ")\n",
    "IEMOCAP_LABEL = (\"angry\", \"happy\", \"neutral\", \"sad\")\n",
    "EMOVO_LABEL = (\"angry\", \"disgust\", \"fear\", \"happy\", \"neutral\", \"sad\", \"surprise\")\n",
    "LABEL_DICT = {\n",
    "    \"CASIA\": CASIA_LABEL,\n",
    "    \"EMODB\": EMODB_LABEL,\n",
    "    \"IEMOCAP\": IEMOCAP_LABEL,\n",
    "    \"EMOVO\": EMOVO_LABEL,\n",
    "    \"SAVEE\": SAVEE_LABEL,\n",
    "    \"RAVDE\": RAVDE_LABEL,\n",
    "}\n",
    "PATH_DICT = {\n",
    "    \"CASIA\": \"./CASIA_MFCC_88\",\n",
    "    \"EMODB\": \"./EMODB_MFCC_96\",\n",
    "    \"IEMOCAP\": \"./IEMOCAP_MFCC_310\",\n",
    "    \"EMOVO\": \"./EMOVO_MFCC_96\",\n",
    "    \"SAVEE\": \"./SAVEE_MFCC_130\",\n",
    "    \"RAVDE\": \"./RAVDE_MFCC_110\",\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Important Note\n",
    "\n",
    "The next cell contains dataset specific code. The raw downloaded datasets need to be organized so that the helper functions can do their job. Here, we sort all the `.wav` files into the emotion based folders named according to the list in the earlier cells.\n",
    "\n",
    "The next cell does the same for the **SAVEE** dataset. For other datasets modify the code accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "pth = \"./Datasets/\" + args.data_name + \"/data/\"\n",
    "if not os.path.exists(pth):\n",
    "    raise Exception(\"Data path does not exist\")\n",
    "\n",
    "SAVEE_icon = {\n",
    "    \"angry\": \"a\",\n",
    "    \"disgust\": \"d\",\n",
    "    \"fear\": \"f\",\n",
    "    \"happy\": \"h\",\n",
    "    \"neutral\": \"n\",\n",
    "    \"sad\": \"sa\",\n",
    "    \"surprise\": \"su\",\n",
    "}\n",
    "\n",
    "df = os.listdir(pth)\n",
    "for i in df:\n",
    "    if i[-4:] != \".wav\":\n",
    "        df.remove(i)\n",
    "df = pd.DataFrame(df)\n",
    "df[\"emotion\"] = df[0].apply(\n",
    "    lambda x: (\n",
    "        x[:-4].split(\"_\")[1][0:2]\n",
    "        if x[:-4].split(\"_\")[1][0] == \"s\"\n",
    "        else x[:-4].split(\"_\")[1][0]\n",
    "    )\n",
    ")\n",
    "\n",
    "for i in SAVEE_icon.keys():\n",
    "    os.makedirs(\"./Datasets/\" + args.data_name + \"/\" + i, exist_ok=True)\n",
    "    for j in df[df[\"emotion\"] == SAVEE_icon[i]][0]:\n",
    "        os.rename(pth + j, \"./Datasets/\" + args.data_name + \"/\" + i + \"/\" + j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Current Folder: /Users/kartik/Desktop/IPR/P1\n",
      "Start to Read angry\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./SAVEE_MFCC_130 build succeed\n",
      "angry build succeed\n",
      "disgust build succeed\n",
      "fear build succeed\n",
      "happy build succeed\n",
      "neutral build succeed\n",
      "sad build succeed\n",
      "surprise build succeed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 60/60 [00:00<00:00, 24263.23it/s]\n",
      "End to Read angry\n",
      "Start to Read disgust\n",
      "100%|██████████| 60/60 [00:00<00:00, 14319.92it/s]\n",
      "End to Read disgust\n",
      "Start to Read fear\n",
      "100%|██████████| 60/60 [00:00<00:00, 17336.61it/s]\n",
      "End to Read fear\n",
      "Start to Read happy\n",
      "100%|██████████| 60/60 [00:00<00:00, 24742.72it/s]\n",
      "End to Read happy\n",
      "Start to Read neutral\n",
      "100%|██████████| 120/120 [00:00<00:00, 8251.90it/s]\n",
      "End to Read neutral\n",
      "Start to Read sad\n",
      "100%|██████████| 60/60 [00:00<00:00, 13452.62it/s]\n",
      "End to Read sad\n",
      "Start to Read surprise\n",
      "100%|██████████| 60/60 [00:00<00:00, 13247.96it/s]\n",
      "End to Read surprise\n",
      "6it [00:00, 24.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Feature Size:(254, 39) ###\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "480it [00:20, 23.10it/s]\n",
      "Current Folder: /Users/kartik/Desktop/IPR/P1\n",
      "Start to Read angry\n",
      "100%|██████████| 60/60 [00:00<00:00, 138.53it/s]\n",
      "End to Read angry\n",
      "Start to Read disgust\n",
      "100%|██████████| 60/60 [00:00<00:00, 301.77it/s]\n",
      "End to Read disgust\n",
      "Start to Read fear\n",
      "100%|██████████| 60/60 [00:00<00:00, 299.94it/s]\n",
      "End to Read fear\n",
      "Start to Read happy\n",
      "100%|██████████| 60/60 [00:00<00:00, 261.40it/s]\n",
      "End to Read happy\n",
      "Start to Read neutral\n",
      "100%|██████████| 120/120 [00:00<00:00, 287.02it/s]\n",
      "End to Read neutral\n",
      "Start to Read sad\n",
      "100%|██████████| 60/60 [00:00<00:00, 332.58it/s]\n",
      "End to Read sad\n",
      "Start to Read surprise\n",
      "100%|██████████| 60/60 [00:00<00:00, 400.21it/s]\n",
      "End to Read surprise\n"
     ]
    }
   ],
   "source": [
    "# First step: extract speech feature\n",
    "extract_feature(\n",
    "    data_name=args.data_name,\n",
    "    feature_type_=\"MFCC\",\n",
    "    mean_signal_length=args.mean_signal_length,\n",
    "    class_labels=LABEL_DICT[args.data_name],\n",
    ")\n",
    "# Second step: convert .csv to .npy\n",
    "x, y = process_csv(\n",
    "    PATH_DICT[args.data_name], class_labels=LABEL_DICT[args.data_name], flatten=False\n",
    ")\n",
    "y = to_categorical(y, num_classes=len(LABEL_DICT[args.data_name]))\n",
    "data = {\"x\": x, \"y\": y}\n",
    "np.save(args.data_name + \".npy\", data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "IPR_P1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
